{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "## EXERCISE: Simple linear regression from scratch\n",
    "\n",
    "[Adapted from Data Science from Scratch, Ch. 14.]\n",
    "\n",
    "For this exercise, we'll build simple linear regression from scratch following the text book.\n",
    "\n",
    "We'll use the data from the book's imaginary social network (DataSciencester):\n",
    "\n",
    "* `num_friends` is the friend count for each user.\n",
    "* `daily_minutes` is the average time spend per day on the site for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_friends = [100,49,41,40,25,21,21,19,19,18,18,16,15,15,15,15,14,14,13,13,13,13,12,12,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,8,8,8,8,8,8,8,8,8,8,8,8,8,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "daily_minutes = [1,68.77,51.25,52.08,38.36,44.54,57.13,51.4,41.42,31.22,34.76,54.01,38.79,47.59,49.1,27.66,41.03,36.73,48.65,28.12,46.62,35.57,32.98,35,26.07,23.77,39.73,40.57,31.65,31.21,36.32,20.45,21.93,26.02,27.34,23.49,46.94,30.5,33.8,24.23,21.4,27.94,32.24,40.57,25.07,19.42,22.39,18.42,46.96,23.72,26.41,26.97,36.76,40.32,35.02,29.47,30.2,31,38.11,38.18,36.31,21.03,30.86,36.07,28.66,29.08,37.28,15.28,24.17,22.31,30.17,25.53,19.85,35.37,44.6,17.23,13.47,26.33,35.02,32.09,24.81,19.33,28.77,24.26,31.98,25.73,24.86,16.28,34.51,15.23,39.72,40.8,26.06,35.76,34.76,16.13,44.04,18.03,19.65,32.62,35.59,39.43,14.18,35.24,40.13,41.82,35.45,36.07,43.67,24.61,20.9,21.9,18.79,27.61,27.21,26.61,29.77,20.59,27.53,13.82,33.2,25,33.1,36.65,18.63,14.87,22.2,36.81,25.53,24.62,26.25,18.21,28.08,19.42,29.79,32.8,35.99,28.32,27.79,35.88,29.06,36.28,14.1,36.63,37.49,26.9,18.58,38.48,24.48,18.95,33.55,14.24,29.04,32.51,25.63,22.22,19,32.73,15.16,13.9,27.2,32.01,29.27,33,13.74,20.42,27.32,18.23,35.35,28.48,9.08,24.62,20.12,35.26,19.92,31.02,16.49,12.16,30.7,31.22,34.65,13.13,27.51,33.2,31.57,14.1,33.42,17.44,10.12,24.42,9.82,23.39,30.93,15.03,21.67,31.09,33.29,22.61,26.89,23.48,8.38,27.81,32.35,23.84]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary maths functions\n",
    "\n",
    "First we'll define some linear algebra and stats functions (from Ch. 4&5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "####\n",
    "#\n",
    "# LINEAR ALGEBRA\n",
    "#\n",
    "####\n",
    "\n",
    "def vector_subtract(v, w):\n",
    "    \"\"\"subtracts two vectors componentwise\"\"\"\n",
    "    return [v_i - w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "####\n",
    "#\n",
    "# STATS\n",
    "#\n",
    "####\n",
    "\n",
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "def de_mean(x):\n",
    "    \"\"\"translate x by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def variance(x):\n",
    "    \"\"\"assumes x has at least two elements\"\"\"\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n - 1)\n",
    "\n",
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))\n",
    "\n",
    "####\n",
    "#\n",
    "# CORRELATION\n",
    "#\n",
    "#####\n",
    "\n",
    "def covariance(x, y):\n",
    "    n = len(x)\n",
    "    return dot(de_mean(x), de_mean(y)) / (n - 1)\n",
    "\n",
    "def correlation(x, y):\n",
    "    stdev_x = standard_deviation(x)\n",
    "    stdev_y = standard_deviation(y)\n",
    "    if stdev_x > 0 and stdev_y > 0:\n",
    "        return covariance(x, y) / stdev_x / stdev_y\n",
    "    else:\n",
    "        return 0 # if no variation, correlation is zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Compare to numpy/scipy\n",
    "\n",
    "- Compare our functions above to the `mean`, `var` and `std` functions from `numpy`. Are the results effectively the same?\n",
    "- Compare the correlation above to the `pearsonr` function from `scipy.stats`. Are the results effectively the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Mostly the same with some small tolerable differences.\n",
    "import numpy as np\n",
    "print('\\nComparing stats for number of friends:')\n",
    "print('-'*47)\n",
    "print('{:15} {:>15} {:>15}'.format('Statistic', 'From Numpy', 'From Scratch'))\n",
    "print('-'*47)\n",
    "for np_fn, sc_fn in [(np.mean, mean), (np.var, variance), (np.std, standard_deviation)]:\n",
    "    print('{:15} {:15.2f} {:15.2f}'.format(np_fn.__name__, np_fn(num_friends), sc_fn(num_friends)))\n",
    "print('-'*47)\n",
    "\n",
    "# 2 - \n",
    "from scipy.stats import pearsonr\n",
    "print('\\nCorrelation from scipy: {:.3f}'.format(pearsonr(num_friends, daily_minutes)[0]))\n",
    "print('Correlation from scratch: {:.3f}'.format(correlation(num_friends, daily_minutes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers\n",
    "\n",
    "Let's have a look at the data.\n",
    "\n",
    "The data point for somebody who has 100 friends but spends 1 minute per day looks like an outlier. Let's remove it (see pages 64-65 of the text book for a discussion).\n",
    "\n",
    "This leads to much stronger correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('\\nScatter plot for daily minutes vs number of friends:')\n",
    "_ = plt.scatter(num_friends, daily_minutes)\n",
    "_ = plt.xlim(0,100)\n",
    "_ = plt.ylim(0,100)\n",
    "_ = plt.xlabel('Number of friends')\n",
    "_ = plt.ylabel('Average minutes per day on site')\n",
    "\n",
    "outlier = num_friends.index(100) # index of outlier\n",
    "\n",
    "num_friends_good = [x\n",
    "                    for i, x in enumerate(num_friends)\n",
    "                    if i != outlier]\n",
    "\n",
    "daily_minutes_good = [x\n",
    "                      for i, x in enumerate(daily_minutes)\n",
    "                      if i != outlier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation before outlier removal: {:.3f}'.format(correlation(num_friends, daily_minutes)))\n",
    "print('Correlation after outlier removal: {:.3f}'.format(correlation(num_friends_good, daily_minutes_good)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression\n",
    "\n",
    "That's the preliminaries all done. Now we can look at linear regression between two variables.\n",
    "\n",
    "Let's assume that we think having more friends causes people to spend more time on the site (see pages 65-67 of the book for a good discussion of caveats and other possible explanations).\n",
    "\n",
    "We're now going to build a simple linear model to describe this relationship.\n",
    "\n",
    "In particular, we assume a model of the form:\n",
    "\n",
    "`y_i = beta * x_i + alpha`\n",
    "\n",
    "Note this takes us right back to [linear equations in algebra](https://en.wikipedia.org/wiki/Linear_equation):\n",
    "\n",
    "`y = mx + b`\n",
    "\n",
    "Looking back at the scatter plot and correlation, this doesn't seems plausible if we assume some noise.\n",
    "\n",
    "Let's see how this works for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(alpha, beta, x_i):\n",
    "    \"\"\"the linear model\n",
    "    alpha and beta are our model parameters\n",
    "    x_i is the data point\n",
    "    return the predicted y value for x_i\"\"\"\n",
    "    return beta * x_i + alpha\n",
    "\n",
    "def error(alpha, beta, x_i, y_i):\n",
    "    \"\"\"the difference between the true y_i\n",
    "    and our predicted y value\"\"\"\n",
    "    return y_i - predict(alpha, beta, x_i)\n",
    "\n",
    "def sum_of_squared_errors(alpha, beta, x, y):\n",
    "    return sum(error(alpha, beta, x_i, y_i) ** 2\n",
    "               for x_i, y_i in zip(x, y))\n",
    "\n",
    "def least_squares_fit(x,y):\n",
    "    \"\"\"given training values for x and y,\n",
    "    find the least-squares values of alpha and beta\"\"\"\n",
    "    beta = correlation(x, y) * standard_deviation(y) / standard_deviation(x)\n",
    "    alpha = mean(y) - beta * mean(x)\n",
    "    return alpha, beta\n",
    "\n",
    "def total_sum_of_squares(y):\n",
    "    \"\"\"the total squared variation of y_i's from their mean\"\"\"\n",
    "    return sum(v ** 2 for v in de_mean(y))\n",
    "\n",
    "def r_squared(alpha, beta, x, y):\n",
    "    \"\"\"the fraction of variation in y captured by the model, which equals\n",
    "    1 - the fraction of variation in y not captured by the model\"\"\"\n",
    "    return 1.0 - (sum_of_squared_errors(alpha, beta, x, y) /\n",
    "                  total_sum_of_squares(y))\n",
    "\n",
    "alpha, beta = least_squares_fit(num_friends_good, daily_minutes_good)\n",
    "print(\"alpha\", alpha)\n",
    "print(\"beta\", beta)\n",
    "\n",
    "r_squared_value = r_squared(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "print(\"r-squared\", r_squared_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Assessing fit and precision\n",
    "\n",
    "R-squared gives an indication of [how well the model fits our data](http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit). It ranges from 0 to 1, with higher values indicating a better fit.\n",
    "\n",
    "Standard error is defined as [the square root of the sum of squared errors divided by N](http://onlinestatbook.com/2/regression/accuracy.html). \n",
    "\n",
    "As a [rule of thumb](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule), we can calculate a 95% confidence interval as [+/- 2 * standard_error from the regression line](http://blog.minitab.com/blog/adventures-in-statistics/regression-analysis-how-to-interpret-s-the-standard-error-of-the-regression).\n",
    "\n",
    "- What r-squared for our model above? Does this indicate a good fit?\n",
    "- Define a `standard_error` function using `sum_of_squared_errors` and `math.sqrt`. What is the standard error of our model?\n",
    "- Redraw the scatterplot from above. This time use `plt.plot` to overlay the regression line and the 95% prediction interval at + and - 2 times the calculated standard error.\n",
    "- Suppose our requirement is that predictions should be +/- 10 minutes of the actual value. Can we say this is with 95% confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - The value here is 0.329. This suggests that our model only partly explains the data\n",
    "#     so there must be other factors at play (see page 176 of the text book).\n",
    "\n",
    "\n",
    "# 2 - \n",
    "def standard_error(alpha, beta, x, y):\n",
    "    return math.sqrt(sum_of_squared_errors(alpha, beta, x, y) / len(y))\n",
    "\n",
    "stderr = standard_error(alpha, beta, num_friends_good, daily_minutes_good)\n",
    "print(\"standard error\", stderr)\n",
    "\n",
    "# 3 - \n",
    "print('\\nScatter plot with regression line and 95% prediction interval:')\n",
    "_ = plt.scatter(num_friends_good, daily_minutes_good)\n",
    "_ = plt.xlim(0,100)\n",
    "_ = plt.ylim(0,100)\n",
    "_ = plt.xlabel('Number of friends')\n",
    "_ = plt.ylabel('Average minutes per day on site')\n",
    "_ = plt.plot([0,100], [predict(alpha,beta,0), predict(alpha,beta,100)], 'r',\n",
    "             [0,100], [predict(alpha,beta,0)-2*stderr, predict(alpha,beta,100)-2*stderr], 'r--',\n",
    "             [0,100], [predict(alpha,beta,0)+2*stderr, predict(alpha,beta,100)+2*stderr], 'r--')\n",
    "\n",
    "# 4 - Nope. The standard error is ~8. 2 * 8 > 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Compare to scipy\n",
    "\n",
    "- Compare our result to the `linregress` function from `scipy.stats`. Are alpha, beta and r-squared the same?\n",
    "- The `scipy` implementation also returns a p-value for the H0 that slope is 0. What is the p-value? Can we reject the H0 at p<=0.01?\n",
    "\n",
    "Note the scipy implementation returns a standard error, but it the error for the slope coefficient instead of the fitting error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - \n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, slope_stderr = linregress(num_friends_good, daily_minutes_good)\n",
    "\n",
    "print('\\nComparing linear regression values:')\n",
    "print('-'*47)\n",
    "print('{:15} {:>15} {:>15}'.format('Statistic', 'From Scipy', 'From Scratch'))\n",
    "print('-'*47)\n",
    "for name, sc_val, sp_val in [(\"alpha\", intercept, alpha),\n",
    "                             (\"beta\", slope, beta),\n",
    "                             (\"r-squared\", r_squared_value, r_value**2)]:\n",
    "    print('{:15} {:15.2f} {:15.2f}'.format(name, sc_val, sp_val))\n",
    "print('-'*47)\n",
    "\n",
    "# 2 - \n",
    "print('\\np-value for a two-sided test of H0 that slope is 0: {}'.format(p_value))\n",
    "print('Can we reject H0?', 'Yes' if p_value<=0.01 else 'No')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Multiple regression\n",
    "\n",
    "\n",
    "\n",
    "Let's at the [Boston Housing data set](https://archive.ics.uci.edu/ml/datasets/Housing). This contains information about housing values by suburb and related information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and visualising data\n",
    "\n",
    "Let's load the data and have a quick look at some descriptive stats for our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def cols_from_rows(data):\n",
    "    cols = [[] for _ in data[0]] # init with empty list for each column\n",
    "    for row in data:\n",
    "        for i, val in enumerate(row):\n",
    "            cols[i].append(val)\n",
    "    return cols\n",
    "\n",
    "print('Descriptive stats for feature values:')\n",
    "cols = cols_from_rows(boston.data)\n",
    "print('-'*65)\n",
    "print('{:10} {:>10} {:>10} {:>10} {:>10} {:>10}'.format('Name', 'Min', 'Max', 'Mean', 'Stdev', 'Median'))\n",
    "print('-'*65)\n",
    "for i, col in enumerate(cols):\n",
    "    print('{:10} {:10.2f} {:10.2f} {:10.2f} {:10.2f} {:10.2f}'\\\n",
    "          .format(boston.feature_names[i], min(col), max(col), np.mean(col), np.std(col), np.median(col)))\n",
    "print('-'*65)\n",
    "    \n",
    "print('\\nBoxplots of feature values:')\n",
    "cols = cols_from_rows(boston.data) + [boston.target]\n",
    "_ = plt.boxplot(cols, vert=False, notch=True, flierprops={'marker':'.'})\n",
    "labels = list(boston.feature_names) + ['VALUE']\n",
    "_ = plt.yticks(range(1,15), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression in scikit-learn\n",
    "\n",
    "Now let's fit a linear model for predicting a suburbs median house value given the other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# First let's create a train and test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(boston.data, boston.target, test_size=0.33,\n",
    "                                                    random_state=5) # so we get the same results\n",
    "\n",
    "# Now let's fit a model\n",
    "lm = LinearRegression()\n",
    "_ = lm.fit(X_train, Y_train)\n",
    "\n",
    "print('Intercept:', lm.intercept_)\n",
    "print('Coefficients:\\n', lm.coef_)\n",
    "print('\\nR-squared:', lm.score(X_train, Y_train))\n",
    "\n",
    "# We use the score method to get r-squared\n",
    "print('\\nR-squared:', lm.score(X_train, Y_train))\n",
    "\n",
    "# We can predict the median price for a new neighbourhoods\n",
    "print('\\nPredicted price of first five neighbourhoods from test split:\\n', lm.predict(X_test)[:5])\n",
    "\n",
    "# We use the score method to get r-squared\n",
    "print('\\nR-squared:', lm.score(X_train, Y_train))\n",
    "\n",
    "# We can also calculate the standard error\n",
    "stderr = math.sqrt(np.mean((Y_train - lm.predict(X_train))**2))\n",
    "print('\\nStandard error:', stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Evaluating predictions \n",
    "\n",
    "- Does r_squared indicate a good fit?\n",
    "- Use `mean_squared_error` from `sklearn.metrics` to calculate standard error. Compare this to the value we calculated in the previous cell.\n",
    "- According to the 95% prediction interval, how close will our predictions be to the actual value? What if we calculate over the test data instead?\n",
    "\n",
    "[Residual plots](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/) scatter residuals (y_true - y_predicted) on the y-axis versus predicted values on the x-axis. A residual plot indicates that a linear model is appropriate if the points are randomly distributed around the `y=0` line.\n",
    "\n",
    "- Draw a residual plot with training data in blue and test data in green. Is a linear model appropriate for our data? Is prediction performance comparable to training performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Yes, r_squared indicates that our model explains the data reasonable well.\n",
    "#     But we should look at standard error as well (page 183 of Data Science from Scratch).\n",
    "\n",
    "# 2 - \n",
    "from sklearn.metrics import mean_squared_error\n",
    "se1 = math.sqrt(np.mean((Y_train - lm.predict(X_train))**2))\n",
    "print('Standard error:', se1)\n",
    "se2 = math.sqrt(mean_squared_error(Y_train, lm.predict(X_train)))\n",
    "print('Standard error using sklearn.metrics:', se2)\n",
    "\n",
    "# 3 - Note we have a fairly small data set (339 in training, 167 in test).\n",
    "#     So this value will vary depending on our split. \n",
    "print('\\nPredictions should be within {:.1f}k dollars at 95% confidence according to training data.'.format(2*se2))\n",
    "se_test = math.sqrt(mean_squared_error(Y_test, lm.predict(X_test)))\n",
    "print('Predictions should be within {:.1f}k dollars at 95% confidence according to test data.'.format(2*se_test))\n",
    "\n",
    "# 4 - Yes the linear model is appropriate\n",
    "print('\\nResidual plot for training data (blue) and test data (green):')\n",
    "_ = plt.scatter(lm.predict(X_train), Y_train-lm.predict(X_train), c='blue', s=40, alpha=0.5, edgecolor='white')\n",
    "_ = plt.scatter(lm.predict(X_test), Y_test-lm.predict(X_test), c='green', s=40, alpha=0.5, edgecolor='white')\n",
    "_ = plt.plot([-10,50], [0,0], c='black')\n",
    "_ = plt.ylabel('Residuals ($y - \\hat{y}$)')\n",
    "_ = plt.xlabel('Predicted values ($\\hat{y}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *STOP PLEASE. THE FOLLOWING IS FOR THE NEXT EXERCISE. THANKS.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Logistic regression\n",
    "\n",
    "\n",
    "\n",
    "We'll use the Iris data set. Like the digits data from week 7, this is another classic machine learning data set.\n",
    "\n",
    "### Loading and visualising data\n",
    "\n",
    "Let's load the data and have a quick look at some descriptive stats for our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def cols_from_rows(data):\n",
    "    cols = [[] for _ in data[0]] # init with empty list for each column\n",
    "    for row in data:\n",
    "        for i, val in enumerate(row):\n",
    "            cols[i].append(val)\n",
    "    return cols\n",
    "\n",
    "print('Descriptive stats for feature values:')\n",
    "cols = cols_from_rows(iris.data)\n",
    "print('-'*75)\n",
    "print('{:20} {:>10} {:>10} {:>10} {:>10} {:>10}'.format('Name', 'Min', 'Max', 'Mean', 'Stdev', 'Median'))\n",
    "print('-'*75)\n",
    "for i, col in enumerate(cols):\n",
    "    print('{:20} {:10.2f} {:10.2f} {:10.2f} {:10.2f} {:10.2f}'\\\n",
    "          .format(iris.feature_names[i], min(col), max(col), np.mean(col), np.std(col), np.median(col)))\n",
    "print('-'*75)\n",
    "    \n",
    "print('\\nBoxplots of feature values:')\n",
    "_ = plt.boxplot(cols_from_rows(iris.data), vert=False, notch=True, flierprops={'marker':'.'})\n",
    "_ = plt.yticks(range(1,5), iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression in scikit-learn\n",
    "\n",
    "Now let's use logistic regression to learn a model of iris type given sepal and petal measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# First let's create a train and test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris.data, iris.target, test_size=0.33,\n",
    "                                                    random_state=5) # so we get the same results\n",
    "\n",
    "# Now let's fit a model\n",
    "logreg = LogisticRegression()\n",
    "_ = logreg.fit(X_train, Y_train)\n",
    "print('Intercept:', logreg.intercept_)\n",
    "print('Coefficients:\\n', logreg.coef_)\n",
    "\n",
    "# We can predict the type of new organisms given measurements\n",
    "print('\\nPredicted type of first five organisms from test split:', logreg.predict(X_test)[:5])\n",
    "print('Actual type of first five organisms from test split:', Y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating classification\n",
    "\n",
    "Recall from week 7 that `sklearn.metrics` includes various evaluation measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "key=', '.join(['{}={}'.format(i,name) for i,name in enumerate(iris.target_names)])\n",
    "print('Classification report ({}):\\n'.format(key))\n",
    "print(classification_report(Y_test, logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Confusion matrix ({}):\\n'.format(key))\n",
    "_ = plt.matshow(confusion_matrix(Y_test, logreg.predict(X_test)), cmap=plt.cm.binary, interpolation='nearest')\n",
    "_ = plt.colorbar()\n",
    "_ = plt.ylabel('true label')\n",
    "_ = plt.xlabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Choose parameters using grid search\n",
    "\n",
    "\n",
    "- Choose the best C values in [1, 10, 100, 1000, 10000, 100000, 1000000] and the best penalty in ['l1', 'l2']\n",
    "- Which is the best C? Which is the best penalty?\n",
    "- How do precision, recall and f1 scores compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000, 1e4, 1e5, 1e6, 1e7], 'penalty': ['l1', 'l2']}\n",
    "]\n",
    "logreg = GridSearchCV(LogisticRegression(), param_grid)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "#print(logreg.cv_results_[{'mean_test_score','std_test_score','params'}])\n",
    "scoring = logreg.cv_results_\n",
    "for mean_score, std, params in zip(scoring['mean_test_score'],scoring['std_test_score'],scoring['params']):\n",
    "    print(\"{:0.3f} (+/-{:0.03f}) for {}\".format(\n",
    "            mean_score, std * 2, params))\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Perform grid search\n",
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000, 1e4, 1e5, 1e6, 1e7], 'penalty': ['l1', 'l2']}\n",
    "]\n",
    "logreg = GridSearchCV(LogisticRegression(), param_grid)\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Print grid search results\n",
    "print('Grid search mean and stdev:\\n')\n",
    "scoring = logreg.cv_results_\n",
    "for mean_score, std, params in zip(scoring['mean_test_score'],scoring['std_test_score'],scoring['params']):\n",
    "    print(\"{:0.3f} (+/-{:0.03f}) for {}\".format(\n",
    "            mean_score, std * 2, params))\n",
    "\n",
    "\n",
    "# Print best params\n",
    "print('\\nBest parameters:', logreg.best_params_)\n",
    "\n",
    "print('\\nClassification report ({}):\\n'.format(key))\n",
    "print(classification_report(Y_test, logreg.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
